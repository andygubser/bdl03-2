{"paragraphs":[{"text":"%md\n# Prototype 1\ndata manipulation with pyspark - failed\n\n## Settings\n* Review active interpreters: md (needs to be on the top), spark2, sh, shUser\n* Review correct file to analyse in %sh and %spark2.pyspark\n\n## Approach\n* get the data by curl\n* do the wide to long transformation with pyspark\n","user":"bd01","dateUpdated":"2021-02-07T16:37:41+0000","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Prototype 1</h1>\n<p>data manipulation with pyspark - failed</p>\n<h2>Settings</h2>\n<ul>\n  <li>Review active interpreters: md (needs to be on the top), spark2, sh, shUser</li>\n  <li>Review correct file to analyse in %sh and %spark2.pyspark</li>\n</ul>\n<h2>Approach</h2>\n<ul>\n  <li>get the data by curl</li>\n  <li>do the wide to long transformation with pyspark</li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1612434548091_398048288","id":"20210127-071031_1944670894","dateCreated":"2021-02-04T10:29:08+0000","dateStarted":"2021-02-05T08:39:54+0000","dateFinished":"2021-02-05T08:39:54+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:19623"},{"text":"%sh\nDIR=/home/zeppelin/project\n\nBASE_URL=\"https://data.open-power-system-data.org/household_data/2020-04-15/\"\n\n# blocksize (HDFS) is 8 MB\n# FILE='household_data_1min_singleindex.csv'        #  1min granularity    # data for project\n# FILE='household_data_15min_singleindex.csv'       # 15min granularity    # data for second prototype\nFILE='household_data_60min_singleindex.csv'       # 60min granualrity    # data for prototype\n\nURL=$BASE_URL/$FILE\n\n# download into the GW - but just once\n\necho \"----create-DIR----\"\ntest -d $DIR || mkdir $DIR\n\necho \"----before-curl---\"\nls -lh $DIR\n\necho \"----after-curl----\"\ntest -f $DIR/$FILE || curl -sSlO $URL\nls -lh $DIR\n\necho \"----hdfs----\"\nhdfs dfs -test -f $FILE      || hdfs dfs -put $DIR/$FILE .\nhdfs dfs -ls /user/$USER\n\n\n","user":"bd01","dateUpdated":"2021-02-04T17:00:50+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"sh","editOnDblClick":false,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/sh","editorHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"----create-DIR----\n----before-curl---\ntotal 925M\n-rw-r--r-- 1 zeppelin hadoop  58M Feb  4 12:35 household_data_15min_singleindex.csv\n-rw-r--r-- 1 zeppelin hadoop 851M Feb  3 17:57 household_data_1min_singleindex.csv\n-rw-r--r-- 1 zeppelin hadoop  15M Feb  4 12:33 household_data_60min_singleindex.csv\n----after-curl----\ntotal 925M\n-rw-r--r-- 1 zeppelin hadoop  58M Feb  4 12:35 household_data_15min_singleindex.csv\n-rw-r--r-- 1 zeppelin hadoop 851M Feb  3 17:57 household_data_1min_singleindex.csv\n-rw-r--r-- 1 zeppelin hadoop  15M Feb  4 12:33 household_data_60min_singleindex.csv\n----hdfs----\nFound 8 items\ndrwxr-xr-x   - zeppelin hdfs          0 2021-02-01 12:12 /user/zeppelin/.sparkStaging\ndrwxr-xr-x   - zeppelin hdfs          0 2021-02-02 09:18 /user/zeppelin/bank2\ndrwxr-xr-x   - zeppelin hdfs          0 2021-02-04 12:57 /user/zeppelin/conf\n-rw-r--r--   1 zeppelin hdfs  892027611 2021-02-03 14:52 /user/zeppelin/household_data_1min_singleindex.csv\n-rw-r--r--   1 zeppelin hdfs   15654559 2021-02-04 13:22 /user/zeppelin/household_data_60min_singleindex.csv\ndrwxr-xr-x   - zeppelin hdfs          0 2021-02-04 10:30 /user/zeppelin/notebook\ndrwxr-xr-x   - zeppelin hdfs          0 2021-01-28 11:18 /user/zeppelin/test\ndrwxr-xr-x   - zeppelin hdfs          0 2021-02-03 18:01 /user/zeppelin/zeppelin\n"}]},"apps":[],"jobName":"paragraph_1612440623508_769971792","id":"20210204-121023_149957682","dateCreated":"2021-02-04T12:10:23+0000","dateStarted":"2021-02-04T13:28:02+0000","dateFinished":"2021-02-04T13:28:07+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:19624"},{"text":"%md\n## DataManipulation with PySpark\n","user":"bd01","dateUpdated":"2021-02-05T08:26:03+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionSupport":false,"completionKey":"TAB"},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>DataManipulation with PySpark</h2>\n</div>"}]},"apps":[],"jobName":"paragraph_1612446944282_1625782149","id":"20210204-135544_129249179","dateCreated":"2021-02-04T13:55:44+0000","dateStarted":"2021-02-05T08:26:03+0000","dateFinished":"2021-02-05T08:26:03+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:19625"},{"text":"%spark2.pyspark\nprint(sc.version)\nprint(sc.pythonVer)\nprint(sc.master)\n","user":"bd01","dateUpdated":"2021-02-04T17:00:50+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionSupport":true,"completionKey":"TAB"},"editorMode":"ace/mode/python","editorHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"2.3.2.3.1.0.0-78\n3.6\nyarn\n"}]},"apps":[],"jobName":"paragraph_1612446115867_-1784103428","id":"20210204-134155_1021688883","dateCreated":"2021-02-04T13:41:55+0000","dateStarted":"2021-02-04T13:42:25+0000","dateFinished":"2021-02-04T13:42:25+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:19626"},{"text":"%spark2.pyspark\nimport os\npath = '/home/zeppelin/project'\n# file = 'household_data_1min_singleindex.csv'        #  1min granularity    # data for project\n# file='household_data_15min_singleindex.csv'       # 15min granularity    # data for second prototype\nfile = 'household_data_60min_singleindex.csv'       # 60min granualrity    # data for prototypeos.chdir(path)\n\npathfile = 'hdfs:///user/{}/{}'.format(os.getenv(\"USER\"),file)\ndf_raw = spark.read.csv(pathfile, header=True, inferSchema=False, sep=\",\")\n","user":"bd01","dateUpdated":"2021-02-04T18:01:05+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python","editorHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://cl-hpsec1-50-gw-01-lx-ub18.lxd:4040/jobs/job?id=96"],"interpreterSettingId":"spark2"}},"apps":[],"jobName":"paragraph_1612440627665_-1015050105","id":"20210204-121027_1126578232","dateCreated":"2021-02-04T12:10:27+0000","dateStarted":"2021-02-04T18:01:05+0000","dateFinished":"2021-02-04T18:01:05+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:19627"},{"text":"%spark2.pyspark\n#df.show(4) # file has to many columns and is not readable with .show()\n#df.schema.names\ndf_raw.printSchema()","user":"bd01","dateUpdated":"2021-02-04T18:01:08+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python","editorHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"root\n |-- utc_timestamp: string (nullable = true)\n |-- cet_cest_timestamp: string (nullable = true)\n |-- DE_KN_industrial1_grid_import: string (nullable = true)\n |-- DE_KN_industrial1_pv_1: string (nullable = true)\n |-- DE_KN_industrial1_pv_2: string (nullable = true)\n |-- DE_KN_industrial2_grid_import: string (nullable = true)\n |-- DE_KN_industrial2_pv: string (nullable = true)\n |-- DE_KN_industrial2_storage_charge: string (nullable = true)\n |-- DE_KN_industrial2_storage_decharge: string (nullable = true)\n |-- DE_KN_industrial3_area_offices: string (nullable = true)\n |-- DE_KN_industrial3_area_room_1: string (nullable = true)\n |-- DE_KN_industrial3_area_room_2: string (nullable = true)\n |-- DE_KN_industrial3_area_room_3: string (nullable = true)\n |-- DE_KN_industrial3_area_room_4: string (nullable = true)\n |-- DE_KN_industrial3_compressor: string (nullable = true)\n |-- DE_KN_industrial3_cooling_aggregate: string (nullable = true)\n |-- DE_KN_industrial3_cooling_pumps: string (nullable = true)\n |-- DE_KN_industrial3_dishwasher: string (nullable = true)\n |-- DE_KN_industrial3_ev: string (nullable = true)\n |-- DE_KN_industrial3_grid_import: string (nullable = true)\n |-- DE_KN_industrial3_machine_1: string (nullable = true)\n |-- DE_KN_industrial3_machine_2: string (nullable = true)\n |-- DE_KN_industrial3_machine_3: string (nullable = true)\n |-- DE_KN_industrial3_machine_4: string (nullable = true)\n |-- DE_KN_industrial3_machine_5: string (nullable = true)\n |-- DE_KN_industrial3_pv_facade: string (nullable = true)\n |-- DE_KN_industrial3_pv_roof: string (nullable = true)\n |-- DE_KN_industrial3_refrigerator: string (nullable = true)\n |-- DE_KN_industrial3_ventilation: string (nullable = true)\n |-- DE_KN_public1_grid_import: string (nullable = true)\n |-- DE_KN_public2_grid_import: string (nullable = true)\n |-- DE_KN_residential1_dishwasher: string (nullable = true)\n |-- DE_KN_residential1_freezer: string (nullable = true)\n |-- DE_KN_residential1_grid_import: string (nullable = true)\n |-- DE_KN_residential1_heat_pump: string (nullable = true)\n |-- DE_KN_residential1_pv: string (nullable = true)\n |-- DE_KN_residential1_washing_machine: string (nullable = true)\n |-- DE_KN_residential2_circulation_pump: string (nullable = true)\n |-- DE_KN_residential2_dishwasher: string (nullable = true)\n |-- DE_KN_residential2_freezer: string (nullable = true)\n |-- DE_KN_residential2_grid_import: string (nullable = true)\n |-- DE_KN_residential2_washing_machine: string (nullable = true)\n |-- DE_KN_residential3_circulation_pump: string (nullable = true)\n |-- DE_KN_residential3_dishwasher: string (nullable = true)\n |-- DE_KN_residential3_freezer: string (nullable = true)\n |-- DE_KN_residential3_grid_export: string (nullable = true)\n |-- DE_KN_residential3_grid_import: string (nullable = true)\n |-- DE_KN_residential3_pv: string (nullable = true)\n |-- DE_KN_residential3_refrigerator: string (nullable = true)\n |-- DE_KN_residential3_washing_machine: string (nullable = true)\n |-- DE_KN_residential4_dishwasher: string (nullable = true)\n |-- DE_KN_residential4_ev: string (nullable = true)\n |-- DE_KN_residential4_freezer: string (nullable = true)\n |-- DE_KN_residential4_grid_export: string (nullable = true)\n |-- DE_KN_residential4_grid_import: string (nullable = true)\n |-- DE_KN_residential4_heat_pump: string (nullable = true)\n |-- DE_KN_residential4_pv: string (nullable = true)\n |-- DE_KN_residential4_refrigerator: string (nullable = true)\n |-- DE_KN_residential4_washing_machine: string (nullable = true)\n |-- DE_KN_residential5_dishwasher: string (nullable = true)\n |-- DE_KN_residential5_grid_import: string (nullable = true)\n |-- DE_KN_residential5_refrigerator: string (nullable = true)\n |-- DE_KN_residential5_washing_machine: string (nullable = true)\n |-- DE_KN_residential6_circulation_pump: string (nullable = true)\n |-- DE_KN_residential6_dishwasher: string (nullable = true)\n |-- DE_KN_residential6_freezer: string (nullable = true)\n |-- DE_KN_residential6_grid_export: string (nullable = true)\n |-- DE_KN_residential6_grid_import: string (nullable = true)\n |-- DE_KN_residential6_pv: string (nullable = true)\n |-- DE_KN_residential6_washing_machine: string (nullable = true)\n |-- interpolated: string (nullable = true)\n\n"}]},"apps":[],"jobName":"paragraph_1612441110756_1093221361","id":"20210204-121830_1414895971","dateCreated":"2021-02-04T12:18:30+0000","dateStarted":"2021-02-04T18:01:08+0000","dateFinished":"2021-02-04T18:01:08+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:19628"},{"text":"%md\n## \"ETL\"","user":"bd01","dateUpdated":"2021-02-04T18:00:15+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionSupport":false,"completionKey":"TAB"},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>&ldquo;ETL&rdquo;</h2>\n</div>"}]},"apps":[],"jobName":"paragraph_1612461603573_-1517850452","id":"20210204-180003_1669074929","dateCreated":"2021-02-04T18:00:03+0000","dateStarted":"2021-02-04T18:00:15+0000","dateFinished":"2021-02-04T18:00:15+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:19629"},{"text":"%md\nI want to split the df into one df for industrial, one df for public, and one df for residential units. \nFurther, I want to transform from the wide format to a long format. I create an additional column indicating the number of the unit. \n\ndf_residential\n\n|unit             |dishwasher       |freezer          |grid_import      |heat_pump        |pv               | washing_maschine|\n|-----------------|-----------------|-----------------|-----------------|-----------------|-----------------|-----------------|\n|                 |                 |                 |                 |                 |                 |                 |","user":"bd01","dateUpdated":"2021-02-04T17:00:50+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>I want to split the df into one df for industrial, one df for public, and one df for residential units.<br/>Further, I want to transform from the wide format to a long format. I create an additional column indicating the number of the unit. </p>\n<p>df_residential</p>\n<table>\n  <thead>\n    <tr>\n      <th>unit </th>\n      <th>dishwasher </th>\n      <th>freezer </th>\n      <th>grid_import </th>\n      <th>heat_pump </th>\n      <th>pv </th>\n      <th>washing_maschine</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td> </td>\n      <td> </td>\n      <td> </td>\n      <td> </td>\n      <td> </td>\n      <td> </td>\n      <td> </td>\n    </tr>\n  </tbody>\n</table>\n</div>"}]},"apps":[],"jobName":"paragraph_1612447061642_-302177401","id":"20210204-135741_172296699","dateCreated":"2021-02-04T13:57:41+0000","dateStarted":"2021-02-04T16:24:45+0000","dateFinished":"2021-02-04T16:24:45+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:19630"},{"text":"%md\n\nTrying to do data manipulation with pyspark, then I moved to the local Pycharm (in need of pandas) on my machine and have uploaded the files to git. \n\n```\n%spark2.pyspark\n\n# functions\n# Split the df\n\nimport re\n\ndef get_cols_of_category(df, str_category):\n    ls_cols_all = df.schema.names\n    ls_cols_additional = [\"utc_timestamp\" , \"cet_cest_timestamp\", \"interpolated\"]\n    return [col for col in ls_cols_all if str_category in col]\nprint(get_cols_of_category(df=df, str_category=\"residential\"))\n    \ndef get_cols_of_category_cleaned(df, str_category):\n    ls_cols_of_category = get_cols_of_category(df, str_category)\n    ls_cols_additional = [\"utc_timestamp\" , \"cet_cest_timestamp\", \"interpolated\"]\n    return ls_cols_additional + list(set([re.sub(f'DE\\_KN\\_{str_category}\\d_', '', col) for col in ls_cols_of_category]))\nprint(get_cols_of_category_cleaned(df=df, str_category=\"residential\"))\n\ndef get_df_relevant(ls_cols, str_category, num):\n    cols_of_category = get_cols_of_category(ls_cols=ls_cols, \n                      str_category=\"residential\", \n                      num=num)\n    df_rel = df.select(cols_of_category).withColumn(\"unit\", lit(num))\n    \n    \n    \n    df_renamed = df_rel.withColumnRenamed(\n        f'DE_KN_residential{num}_pv', 'pv'\n        ).withColumnRenamed(\n            f'DE_KN_residential{num}_dishwasher', 'dishwasher'\n            ).withColumnRenamed(\n                f'DE_KN_residential{num}_washing_machine', 'washing_machine'\n                ).withColumnRenamed(\n                    f'DE_KN_residential{num}_heat_pump', 'heat_pump'\n                    ).withColumnRenamed(\n                        f'DE_KN_residential{num}_freezer', 'freezer'\n                        ).withColumnRenamed(\n                            f'DE_KN_residential{num}_grid_import', 'grid_import'\n                            ).withColumnRenamed(\n                                f'DE_KN_residential{num}_grid_export', 'grid_export'\n                                ).withColumnRenamed(\n                                f'DE_KN_residential{num}_circulation_pump', 'circulation_pump'\n                                ).withColumnRenamed(\n                                    f'DE_KN_residential{num}_refrigerator','refrigerator'\n                                    )\n    \n    return df_renamed\n    \n\ndf_residential1 = get_df_relevant(ls_cols=ls_cols,\n                                  str_category=\"residential\",\n                                  num=1)\ndf_residential2 = get_df_relevant(ls_cols=ls_cols,\n                                  str_category=\"residential\",\n                                  num=2)\ndf_residential3 = get_df_relevant(ls_cols=ls_cols,\n                                  str_category=\"residential\",\n                                  num=3)\ndf_residential4 = get_df_relevant(ls_cols=ls_cols,\n                                  str_category=\"residential\",\n                                  num=4)\ndf_residential5 = get_df_relevant(ls_cols=ls_cols,\n                                  str_category=\"residential\",\n                                  num=5)\ndf_residential6 = get_df_relevant(ls_cols=ls_cols,\n                                  str_category=\"residential\",\n                                  num=6)\n    \n```\n\n    ","user":"bd01","dateUpdated":"2021-02-05T09:59:17+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionSupport":false,"completionKey":"TAB"},"editorMode":"ace/mode/markdown","editorHide":false,"tableHide":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Trying to do data manipulation with pyspark, then I moved to the local Pycharm (in need of pandas) on my machine and have uploaded the files to git. </p>\n<pre><code>%spark2.pyspark\n\n# functions\n# Split the df\n\nimport re\n\ndef get_cols_of_category(df, str_category):\n    ls_cols_all = df.schema.names\n    ls_cols_additional = [&quot;utc_timestamp&quot; , &quot;cet_cest_timestamp&quot;, &quot;interpolated&quot;]\n    return [col for col in ls_cols_all if str_category in col]\nprint(get_cols_of_category(df=df, str_category=&quot;residential&quot;))\n    \ndef get_cols_of_category_cleaned(df, str_category):\n    ls_cols_of_category = get_cols_of_category(df, str_category)\n    ls_cols_additional = [&quot;utc_timestamp&quot; , &quot;cet_cest_timestamp&quot;, &quot;interpolated&quot;]\n    return ls_cols_additional + list(set([re.sub(f&#39;DE\\_KN\\_{str_category}\\d_&#39;, &#39;&#39;, col) for col in ls_cols_of_category]))\nprint(get_cols_of_category_cleaned(df=df, str_category=&quot;residential&quot;))\n\ndef get_df_relevant(ls_cols, str_category, num):\n    cols_of_category = get_cols_of_category(ls_cols=ls_cols, \n                      str_category=&quot;residential&quot;, \n                      num=num)\n    df_rel = df.select(cols_of_category).withColumn(&quot;unit&quot;, lit(num))\n    \n    \n    \n    df_renamed = df_rel.withColumnRenamed(\n        f&#39;DE_KN_residential{num}_pv&#39;, &#39;pv&#39;\n        ).withColumnRenamed(\n            f&#39;DE_KN_residential{num}_dishwasher&#39;, &#39;dishwasher&#39;\n            ).withColumnRenamed(\n                f&#39;DE_KN_residential{num}_washing_machine&#39;, &#39;washing_machine&#39;\n                ).withColumnRenamed(\n                    f&#39;DE_KN_residential{num}_heat_pump&#39;, &#39;heat_pump&#39;\n                    ).withColumnRenamed(\n                        f&#39;DE_KN_residential{num}_freezer&#39;, &#39;freezer&#39;\n                        ).withColumnRenamed(\n                            f&#39;DE_KN_residential{num}_grid_import&#39;, &#39;grid_import&#39;\n                            ).withColumnRenamed(\n                                f&#39;DE_KN_residential{num}_grid_export&#39;, &#39;grid_export&#39;\n                                ).withColumnRenamed(\n                                f&#39;DE_KN_residential{num}_circulation_pump&#39;, &#39;circulation_pump&#39;\n                                ).withColumnRenamed(\n                                    f&#39;DE_KN_residential{num}_refrigerator&#39;,&#39;refrigerator&#39;\n                                    )\n    \n    return df_renamed\n    \n\ndf_residential1 = get_df_relevant(ls_cols=ls_cols,\n                                  str_category=&quot;residential&quot;,\n                                  num=1)\ndf_residential2 = get_df_relevant(ls_cols=ls_cols,\n                                  str_category=&quot;residential&quot;,\n                                  num=2)\ndf_residential3 = get_df_relevant(ls_cols=ls_cols,\n                                  str_category=&quot;residential&quot;,\n                                  num=3)\ndf_residential4 = get_df_relevant(ls_cols=ls_cols,\n                                  str_category=&quot;residential&quot;,\n                                  num=4)\ndf_residential5 = get_df_relevant(ls_cols=ls_cols,\n                                  str_category=&quot;residential&quot;,\n                                  num=5)\ndf_residential6 = get_df_relevant(ls_cols=ls_cols,\n                                  str_category=&quot;residential&quot;,\n                                  num=6)\n    \n</code></pre>\n</div>"}]},"apps":[],"jobName":"paragraph_1612445870499_-1002688052","id":"20210204-133750_1506957959","dateCreated":"2021-02-04T13:37:50+0000","dateStarted":"2021-02-05T08:36:45+0000","dateFinished":"2021-02-05T08:36:45+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:19631"}],"name":"MEP / wdgubser / 500 Prototype 1","id":"2FX9Q8A1U","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"shUser:bd01:":[],"sh:shared_process":[],"spark2:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}